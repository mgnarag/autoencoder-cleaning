{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgnarag/binarization-autoencoder/blob/main/Finetuning_model6b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fine tuning**"
      ],
      "metadata": {
        "id": "MgrVS8ndDXQm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")\n",
        "!ls drive/My\\ Drive\n",
        "file_path = \"/content/drive/My Drive/Architectural_designs/one quadrant/\""
      ],
      "metadata": {
        "id": "vboHIA7xDZz3",
        "outputId": "e7281ecf-58bc-43db-afb5-b4ba9a6cec53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            " 1872_Mindanao_NAP_D.FedericoCaballero.tif\n",
            " 1885_Mactan_NAP_FelixPelayo.tiff\n",
            " 201464423-23022858-PaymentSlip.pdf\n",
            " 313490484_646790150357239_663796780442369775_n.jpg\n",
            " 361079911_248325231393045_2145216296096417082_n.jpg\n",
            "'Applied Physics 184 FX-2'\n",
            " Architectural_designs\n",
            " autoencoder_32\n",
            "'autoencoder_32 (1)'\n",
            " autoencoder_64\n",
            "'BS Applied Physics'\n",
            " Classroom\n",
            "'CLEAN_[WB] 1872_Mindanao_NAP_D (1).FedericoCaballero.tif'\n",
            "'CLEAN_[WB] 1872_Mindanao_NAP_D (2).FedericoCaballero.tif'\n",
            "'CLEAN_[WB] 1872_Mindanao_NAP_D (3).FedericoCaballero.tif'\n",
            "'CLEAN_[WB] 1872_Mindanao_NAP_D.FedericoCaballero.tif'\n",
            "'CNN scores.gsheet'\n",
            "'Colab Notebooks'\n",
            "'CONSENT_NARAG_MARK JEREMY_G.pdf'\n",
            " CONSENT_NARAG_MARKJEREMY_G.pdf\n",
            " CS284\n",
            "'Dorm bill.png'\n",
            " Fast-Dreambooth\n",
            "'fingerprint (1).pb'\n",
            "'fingerprint (2).pb'\n",
            " fingerprint.pb\n",
            " FN.png\n",
            " FP.png\n",
            " GAN\n",
            "'Geology (Ate Grass)'\n",
            "'Getting started.pdf'\n",
            " image.jpg\n",
            " IMG_5032.jpeg\n",
            " IMG_6546.PNG\n",
            "'IMG_9359 (1).PNG'\n",
            " IMG_9359.PNG\n",
            "'Information Sharing Consent Form - NARAG.pdf'\n",
            "'Information Sharing Consent Form.pdf'\n",
            " Jem_face\n",
            " Jem_face_2\n",
            " Jem_facemetadata.jsonl\n",
            "'[Journal of Cultural Heritage] Discovering artistic influences of painters'\n",
            " LORA\n",
            "'loss_32 (1).csv'\n",
            " loss_32.csv\n",
            "'loss_64 (1).csv'\n",
            " loss_64.csv\n",
            "'MALIPOL_CHAE ANN.pdf'\n",
            "'March 13 2024 Pigment Reflectance.gsheet'\n",
            "'Metric_100DPI_white balanced and bw output_1.csv'\n",
            "'model 64'\n",
            "'model grayscale output'\n",
            "'MS PHYSICS'\n",
            "'MS Thesis videos'\n",
            "'NARAG, MARK JEREMY, GACIAS.gdoc'\n",
            "'NARAG, MARK JEREMY, GACIAS.pdf'\n",
            "'NARAG, MARK JEREMY.jpg'\n",
            " NIP_Narag_MarkJeremy_Consent.pdf\n",
            " NIP_Narag_MarkJeremy_Informal.jpg\n",
            " NIP_Narag_MarkJeremy_Sablay.jpg\n",
            "'output v1_blue (1).png'\n",
            "'output v1_blue.png'\n",
            "'output v1_gray (1).png'\n",
            "'output v1_gray.png'\n",
            "'output v1_green (1).png'\n",
            "'output v1_green.png'\n",
            "'output v1_red (1).png'\n",
            "'output v1_red.png'\n",
            "'output v1_RGB (1).png'\n",
            "'output v1_RGB_GRAY (1).png'\n",
            "'output v1_RGB_GRAY.png'\n",
            "'output v1_RGB.png'\n",
            "'output v2_blue (1).png'\n",
            "'output v2_blue.png'\n",
            "'output v2_gray (1).png'\n",
            "'output v2_gray.png'\n",
            "'output v2_green (1).png'\n",
            "'output v2_green.png'\n",
            "'output v2_red (1).png'\n",
            "'output v2_red.png'\n",
            "'output v2_RGB (1).png'\n",
            "'output v2_RGB_GRAY (1).png'\n",
            "'output v2_RGB_GRAY.png'\n",
            "'output v2_RGB.png'\n",
            "'output v3_blue (1).png'\n",
            "'output v3_blue.png'\n",
            "'output v3_gray (1).png'\n",
            "'output v3_gray.png'\n",
            "'output v3_green (1).png'\n",
            "'output v3_green.png'\n",
            "'output v3_red (1).png'\n",
            "'output v3_red.png'\n",
            "'output v3_RGB (1).png'\n",
            "'output v3_RGB_GRAY (1).png'\n",
            "'output v3_RGB_GRAY.png'\n",
            "'output v3_RGB.png'\n",
            "'output v4_blue (1).png'\n",
            "'output v4_blue.png'\n",
            "'output v4_gray (1).png'\n",
            "'output v4_gray.png'\n",
            "'output v4_green (1).png'\n",
            "'output v4_green.png'\n",
            "'output v4_red (1).png'\n",
            "'output v4_red.png'\n",
            "'output v4_RGB (1).png'\n",
            "'output v4_RGB_GRAY (1).png'\n",
            "'output v4_RGB_GRAY.png'\n",
            "'output v4_RGB.png'\n",
            "'output v5_blue (1).png'\n",
            "'output v5_blue.png'\n",
            "'output v5_gray (1).png'\n",
            "'output v5_gray.png'\n",
            "'output v5_green (1).png'\n",
            "'output v5_green.png'\n",
            "'output v5_red (1).png'\n",
            "'output v5_red.png'\n",
            "'output v5_RGB (1).png'\n",
            "'output v5_RGB_GRAY (1).png'\n",
            "'output v5_RGB_GRAY.png'\n",
            "'output v5_RGB.png'\n",
            "'output v6_blue (1).png'\n",
            "'output v6_blue.png'\n",
            "'output v6_gray (1).png'\n",
            "'output v6_gray.png'\n",
            "'output v6_green (1).png'\n",
            "'output v6_green.png'\n",
            "'output v6_red.png'\n",
            "'output v6_RGB (1).png'\n",
            "'output v6_RGB_GRAY (1).png'\n",
            "'output v6_RGB_GRAY.png'\n",
            "'output v6_RGB.png'\n",
            "'PEHA 2021 Consent Form (fillable).pdf'\n",
            "'PhD PHYSICS'\n",
            "'PHOTO_NARAG_MARK JEREMY_G.jpg'\n",
            " PHOTO_NARAG_MARKJEREMY_G.jpg\n",
            "'Physics 265'\n",
            "'Physics 301 2S AY2122'\n",
            "'Physics 305 Data Driven Astronomy'\n",
            "'Research files'\n",
            " Rizal_input.png\n",
            "'Sanyata journal'\n",
            "'saved_model (1).pb'\n",
            "'saved_model (2).pb'\n",
            " saved_model.pb\n",
            "'Screen Shot 2022-08-31 at 10.46.42.png'\n",
            "'Screen Shot 2022-09-13 at 12.40.21.png'\n",
            "'Screen Shot 2022-09-13 at 12.43.14.png'\n",
            " sd\n",
            "'SPP 2022'\n",
            " TP.png\n",
            " unet_64\n",
            "'Untitled document.gdoc'\n",
            "'UP CRS - Outstanding Transactions.pdf'\n",
            "'Vaccination Card (1).jpg'\n",
            "'Vaccination Card.jpg'\n",
            "'val_loss_32 (1).csv'\n",
            " val_loss_32.csv\n",
            "'val_loss_64 (1).csv'\n",
            " val_loss_64.csv\n",
            "'variables (1).data-00000-of-00001'\n",
            "'variables (2).data-00000-of-00001'\n",
            " variables.data-00000-of-00001\n",
            "'[WB] 1872_Mindanao_NAP_D.FedericoCaballero.tif'\n",
            "'[WB] 1885_Mactan_NAP_FelixPelayo.png'\n",
            "'[WB] XXXX_Cagayan y Ilocos_online.png'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "epoch = 100\n",
        "model_number = 6\n",
        "size = 128\n",
        "\n",
        "def crop(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "\n",
        "    for j in np.arange(0,int(height/size)+1,0.3775):\n",
        "        for i in np.arange(0,int(width/size)+1,0.3775):\n",
        "            im1 = im.crop((0 + (size*i), 0 + (size*j), size + (size*i), size + (size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            im1 = im1/255\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_input = np.array(crop(ImageOps.grayscale(Image.open(file_path + \"final_input_train.png\"))))\n",
        "print(\"Done reading the  training input of size = \", train_input.shape)\n",
        "\n",
        "train_output = np.array(crop(ImageOps.grayscale(Image.open(file_path + \"cleaned_output_train.png\"))))\n",
        "print(\"Done reading the  training out of size = \", train_output.shape)\n",
        "\n",
        "test_input = np.array(crop(ImageOps.grayscale(Image.open(file_path + \"final_input_test.png\"))))\n",
        "print(\"Done reading the  test input of size = \", test_input.shape)\n",
        "\n",
        "test_output = np.array(crop(ImageOps.grayscale(Image.open(file_path + \"cleaned_output_test.png\"))))\n",
        "print(\"Done reading the  test output of size = \", test_output.shape)\n",
        "#'''\n",
        "data = []"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnW6cUYy_bXI",
        "outputId": "1e28128f-3e73-4571-ae2d-c35db188d7ca"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done reading the  training input of size =  (22484, 128, 128)\n",
            "Done reading the  training out of size =  (22484, 128, 128)\n",
            "Done reading the  test input of size =  (9394, 128, 128)\n",
            "Done reading the  test output of size =  (9394, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def load_images_from_folder(folder_path, size, test_size):\n",
        "    images = []\n",
        "    filenames = sorted(os.listdir(folder_path))\n",
        "    for filename in filenames:\n",
        "        img_path = os.path.join(folder_path, filename)\n",
        "        if os.path.isfile(img_path):\n",
        "            im = ImageOps.grayscale(Image.open(img_path))\n",
        "            images.extend(crop(im))\n",
        "    # Split the images into training and validation sets\n",
        "    X_train, X_val = train_test_split(images, test_size=test_size, random_state=42)\n",
        "    return np.array(X_train), np.array(X_val)\n",
        "\n",
        "input_folder_path = file_path+\"7 Fine tuning/input\"\n",
        "output_folder_path = file_path+\"7 Fine tuning/output\"\n",
        "size = 128\n",
        "test_size = 0.2\n",
        "\n",
        "# Load input and output images, split into training and validation sets\n",
        "train_input_add, test_input_add = load_images_from_folder(input_folder_path, size, test_size)\n",
        "train_output_add, test_output_add = load_images_from_folder(output_folder_path, size, test_size)\n",
        "\n",
        "\n",
        "train_input = np.concatenate((train_input,train_input_add))\n",
        "train_output = np.concatenate((train_output,train_output_add))\n",
        "test_input = np.concatenate((test_input,test_input_add))\n",
        "test_output = np.concatenate((test_output,test_output_add))\n",
        "\n",
        "\n",
        "print(\"Training input adding:\", train_input_add.shape)\n",
        "print(\"Validation input adding:\", test_input_add.shape)\n",
        "print(\"Training output adding:\", train_output_add.shape)\n",
        "print(\"Validation output adding:\", test_output_add.shape)\n",
        "\n",
        "\n",
        "print(\"Training input size after adding:\", train_input.shape)\n",
        "print(\"Validation input size  after adding:\", test_input.shape)\n",
        "print(\"Training output size  after adding:\", train_output.shape)\n",
        "print(\"Validation output size  after adding:\", test_output.shape)\n",
        "\n",
        "images = []\n",
        "train_input_add = []\n",
        "train_output_add = []\n",
        "test_input_add = []\n",
        "test_output_add = []"
      ],
      "metadata": {
        "id": "WziVlm16G9Ts",
        "outputId": "bfaf4960-8261-4f5f-ed31-36250403cf8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training input adding: (6873, 128, 128)\n",
            "Validation input adding: (1719, 128, 128)\n",
            "Training output adding: (6873, 128, 128)\n",
            "Validation output adding: (1719, 128, 128)\n",
            "Training input size after adding: (29357, 128, 128)\n",
            "Validation input size  after adding: (11113, 128, 128)\n",
            "Training output size  after adding: (29357, 128, 128)\n",
            "Validation output size  after adding: (11113, 128, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "N = 29000\n",
        "n=10\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(0,10):\n",
        "\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.title(\"input\")\n",
        "    plt.imshow((train_input[i+N]))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    bx = plt.subplot(2, n, i + n + 1)\n",
        "    plt.title(\"output\")\n",
        "    plt.imshow((train_output[i+N]))\n",
        "    plt.gray()\n",
        "    bx.get_xaxis().set_visible(False)\n",
        "    bx.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "wUb6e2ImIyBY",
        "outputId": "a31b2fc7-610b-4da7-cabd-1e21fc8cadf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 20 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class autoenc(Model):\n",
        "  def __init__(self):\n",
        "    super(autoenc, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Input(shape=(size, size, 1)),\n",
        "      layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides=2)])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Conv2DTranspose(64, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = autoenc()\n",
        "\n",
        "\n",
        "#autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "learning_rate = 0.01  # You can adjust this value as needed\n",
        "\n",
        "autoencoder.compile(optimizer=Adam(learning_rate=learning_rate), loss=losses.MeanSquaredError())\n",
        "\n",
        "\n",
        "model = autoencoder.fit(train_input, train_output,\n",
        "                epochs=100,\n",
        "                shuffle=True,\n",
        "                validation_data=(test_input, test_output))\n",
        "\n",
        "autoencoder.encoder.summary()\n",
        "\n",
        "\n",
        "# Save the fine-tuned model\n",
        "autoencoder.save(file_path + '7 Fine tuning/' + 'v3_autoencoder_'+str(model_number)+'_b')\n",
        "\n",
        "# Save the fine-tune history\n",
        "fine_tune_loss = model.history['loss']\n",
        "fine_tune_loss_df = pd.DataFrame(fine_tune_loss)\n",
        "fine_tune_loss_df.to_csv(file_path + '7 Fine tuning/' + 'v3_loss_'+str(model_number)+'_b.csv')\n",
        "\n",
        "fine_tune_val_loss = model.history['val_loss']\n",
        "fine_tune_val_loss_df = pd.DataFrame(fine_tune_val_loss)\n",
        "fine_tune_val_loss_df.to_csv(file_path + '7 Fine tuning/' +'v3_val_loss_'+str(model_number)+'_b.csv')\n",
        "\n",
        "\n",
        "# record end time\n",
        "end = time.time()\n",
        "\n",
        "print(\"The time of execution of above program is :\",\n",
        "      (end-start), \"seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWAViueiBGfN",
        "outputId": "ded62232-8291-4575-e9f1-cecea983d99e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "918/918 [==============================] - 22s 19ms/step - loss: 0.0263 - val_loss: 0.0144\n",
            "Epoch 2/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0165 - val_loss: 0.0127\n",
            "Epoch 3/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0153 - val_loss: 0.0121\n",
            "Epoch 4/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0149 - val_loss: 0.0126\n",
            "Epoch 5/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0146 - val_loss: 0.0112\n",
            "Epoch 6/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0143 - val_loss: 0.0116\n",
            "Epoch 7/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0138 - val_loss: 0.0113\n",
            "Epoch 8/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0136 - val_loss: 0.0108\n",
            "Epoch 9/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0135 - val_loss: 0.0109\n",
            "Epoch 10/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0134 - val_loss: 0.0103\n",
            "Epoch 11/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0132 - val_loss: 0.0102\n",
            "Epoch 12/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0130 - val_loss: 0.0107\n",
            "Epoch 13/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0130 - val_loss: 0.0107\n",
            "Epoch 14/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0128 - val_loss: 0.0102\n",
            "Epoch 15/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0127 - val_loss: 0.0101\n",
            "Epoch 16/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0127 - val_loss: 0.0095\n",
            "Epoch 17/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0126 - val_loss: 0.0098\n",
            "Epoch 18/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0125 - val_loss: 0.0104\n",
            "Epoch 19/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0124 - val_loss: 0.0098\n",
            "Epoch 20/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0125 - val_loss: 0.0101\n",
            "Epoch 21/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0124 - val_loss: 0.0096\n",
            "Epoch 22/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0122 - val_loss: 0.0097\n",
            "Epoch 23/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0122 - val_loss: 0.0094\n",
            "Epoch 24/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0122 - val_loss: 0.0102\n",
            "Epoch 25/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0122 - val_loss: 0.0097\n",
            "Epoch 26/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0122 - val_loss: 0.0098\n",
            "Epoch 27/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0121 - val_loss: 0.0094\n",
            "Epoch 28/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0121 - val_loss: 0.0094\n",
            "Epoch 29/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0121 - val_loss: 0.0120\n",
            "Epoch 30/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0121 - val_loss: 0.0094\n",
            "Epoch 31/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0120 - val_loss: 0.0098\n",
            "Epoch 32/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0120 - val_loss: 0.0106\n",
            "Epoch 33/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0120 - val_loss: 0.0091\n",
            "Epoch 34/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0119 - val_loss: 0.0096\n",
            "Epoch 35/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0120 - val_loss: 0.0094\n",
            "Epoch 36/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0120 - val_loss: 0.0098\n",
            "Epoch 37/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0119 - val_loss: 0.0091\n",
            "Epoch 38/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0119 - val_loss: 0.0090\n",
            "Epoch 39/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0118 - val_loss: 0.0100\n",
            "Epoch 40/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0118 - val_loss: 0.0087\n",
            "Epoch 41/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0118 - val_loss: 0.0096\n",
            "Epoch 42/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0118 - val_loss: 0.0091\n",
            "Epoch 43/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0118 - val_loss: 0.0100\n",
            "Epoch 44/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0117 - val_loss: 0.0091\n",
            "Epoch 45/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0117 - val_loss: 0.0092\n",
            "Epoch 46/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0117 - val_loss: 0.0092\n",
            "Epoch 47/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0117 - val_loss: 0.0097\n",
            "Epoch 48/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0117 - val_loss: 0.0093\n",
            "Epoch 49/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0116 - val_loss: 0.0088\n",
            "Epoch 50/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0117 - val_loss: 0.0092\n",
            "Epoch 51/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0117 - val_loss: 0.0087\n",
            "Epoch 52/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0116 - val_loss: 0.0090\n",
            "Epoch 53/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0117 - val_loss: 0.0089\n",
            "Epoch 54/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0116 - val_loss: 0.0086\n",
            "Epoch 55/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0116 - val_loss: 0.0087\n",
            "Epoch 56/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0116 - val_loss: 0.0088\n",
            "Epoch 57/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0116 - val_loss: 0.0086\n",
            "Epoch 58/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0116 - val_loss: 0.0091\n",
            "Epoch 59/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0115 - val_loss: 0.0091\n",
            "Epoch 60/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0115 - val_loss: 0.0096\n",
            "Epoch 61/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0116 - val_loss: 0.0092\n",
            "Epoch 62/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0115 - val_loss: 0.0088\n",
            "Epoch 63/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0115 - val_loss: 0.0087\n",
            "Epoch 64/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0115 - val_loss: 0.0085\n",
            "Epoch 65/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0115 - val_loss: 0.0089\n",
            "Epoch 66/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0115 - val_loss: 0.0085\n",
            "Epoch 67/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0089\n",
            "Epoch 68/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0088\n",
            "Epoch 69/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0091\n",
            "Epoch 70/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0115 - val_loss: 0.0087\n",
            "Epoch 71/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0115 - val_loss: 0.0087\n",
            "Epoch 72/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0086\n",
            "Epoch 73/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0089\n",
            "Epoch 74/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0087\n",
            "Epoch 75/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0115 - val_loss: 0.0089\n",
            "Epoch 76/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0086\n",
            "Epoch 77/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0115 - val_loss: 0.0086\n",
            "Epoch 78/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0083\n",
            "Epoch 79/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0087\n",
            "Epoch 80/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0115 - val_loss: 0.0088\n",
            "Epoch 81/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0088\n",
            "Epoch 82/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0113 - val_loss: 0.0084\n",
            "Epoch 83/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0085\n",
            "Epoch 84/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0087\n",
            "Epoch 85/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0092\n",
            "Epoch 86/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0094\n",
            "Epoch 87/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0113 - val_loss: 0.0089\n",
            "Epoch 88/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0086\n",
            "Epoch 89/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0113 - val_loss: 0.0095\n",
            "Epoch 90/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0086\n",
            "Epoch 91/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0113 - val_loss: 0.0099\n",
            "Epoch 92/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0114 - val_loss: 0.0084\n",
            "Epoch 93/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0113 - val_loss: 0.0088\n",
            "Epoch 94/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0113 - val_loss: 0.0083\n",
            "Epoch 95/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0113 - val_loss: 0.0083\n",
            "Epoch 96/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0113 - val_loss: 0.0085\n",
            "Epoch 97/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0113 - val_loss: 0.0083\n",
            "Epoch 98/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0113 - val_loss: 0.0082\n",
            "Epoch 99/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0113 - val_loss: 0.0084\n",
            "Epoch 100/100\n",
            "918/918 [==============================] - 14s 15ms/step - loss: 0.0112 - val_loss: 0.0083\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 64, 64)        640       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 640 (2.50 KB)\n",
            "Trainable params: 640 (2.50 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "The time of execution of above program is : 1407.8489491939545 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start = time.time()\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import load_model\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "model_number = 6\n",
        "# Load your saved model\n",
        "autoencoder = load_model(file_path + '1 Models/' + 'autoencoder_'+str(model_number) + '_b')\n",
        "\n",
        "# Freeze layers to prevent retraining\n",
        "for layer in autoencoder.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Compile the model with custom learning parameters\n",
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "\n",
        "# Fine-tune the model\n",
        "fine_tune_history = autoencoder.fit(train_input, train_output,\n",
        "                                     epochs=1000,\n",
        "                                     shuffle=True,\n",
        "                                     validation_data=(val_input, val_output))\n",
        "\n",
        "# Save the fine-tuned model\n",
        "autoencoder.save(file_path + '7 Fine tuning/' + 'autoencoder_fine_tuned_'+str(model_number))\n",
        "\n",
        "# Save the fine-tune history\n",
        "fine_tune_loss = fine_tune_history.history['loss']\n",
        "fine_tune_loss_df = pd.DataFrame(fine_tune_loss)\n",
        "fine_tune_loss_df.to_csv(file_path + '7 Fine tuning/' + 'fine_tune_loss_'+str(model_number)+'.csv')\n",
        "\n",
        "fine_tune_val_loss = fine_tune_history.history['val_loss']\n",
        "fine_tune_val_loss_df = pd.DataFrame(fine_tune_val_loss)\n",
        "fine_tune_val_loss_df.to_csv(file_path + '7 Fine tuning/' +'fine_tune_val_loss_'+str(model_number)+'.csv')\n",
        "\n",
        "# Record end time\n",
        "end = time.time()\n",
        "\n",
        "print(\"The time of execution of the fine-tuning program is:\", (end - start), \"seconds\")"
      ],
      "metadata": {
        "id": "U8XfcN8lDdg3",
        "outputId": "c1a2df74-e400-4ee1-a644-0a449011535d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "215/215 [==============================] - 15s 44ms/step - loss: 0.0291 - val_loss: 0.0263\n",
            "Epoch 2/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0242 - val_loss: 0.0249\n",
            "Epoch 3/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0231 - val_loss: 0.0255\n",
            "Epoch 4/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0227 - val_loss: 0.0231\n",
            "Epoch 5/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0221 - val_loss: 0.0230\n",
            "Epoch 6/1000\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.0216 - val_loss: 0.0222\n",
            "Epoch 7/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0215 - val_loss: 0.0228\n",
            "Epoch 8/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0213 - val_loss: 0.0220\n",
            "Epoch 9/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0210 - val_loss: 0.0218\n",
            "Epoch 10/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0210 - val_loss: 0.0216\n",
            "Epoch 11/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0209 - val_loss: 0.0215\n",
            "Epoch 12/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0207 - val_loss: 0.0214\n",
            "Epoch 13/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0206 - val_loss: 0.0218\n",
            "Epoch 14/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0206 - val_loss: 0.0214\n",
            "Epoch 15/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0206 - val_loss: 0.0212\n",
            "Epoch 16/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0205 - val_loss: 0.0213\n",
            "Epoch 17/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0205 - val_loss: 0.0212\n",
            "Epoch 18/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0204 - val_loss: 0.0212\n",
            "Epoch 19/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0204 - val_loss: 0.0211\n",
            "Epoch 20/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0203 - val_loss: 0.0211\n",
            "Epoch 21/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0203 - val_loss: 0.0211\n",
            "Epoch 22/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0203 - val_loss: 0.0209\n",
            "Epoch 23/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0202 - val_loss: 0.0210\n",
            "Epoch 24/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0202 - val_loss: 0.0209\n",
            "Epoch 25/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0202 - val_loss: 0.0208\n",
            "Epoch 26/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0201 - val_loss: 0.0210\n",
            "Epoch 27/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0200 - val_loss: 0.0206\n",
            "Epoch 28/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0201 - val_loss: 0.0207\n",
            "Epoch 29/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0201 - val_loss: 0.0212\n",
            "Epoch 30/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0199 - val_loss: 0.0206\n",
            "Epoch 31/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0200 - val_loss: 0.0207\n",
            "Epoch 32/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0199 - val_loss: 0.0206\n",
            "Epoch 33/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0199 - val_loss: 0.0212\n",
            "Epoch 34/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0199 - val_loss: 0.0205\n",
            "Epoch 35/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0199 - val_loss: 0.0205\n",
            "Epoch 36/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0197 - val_loss: 0.0212\n",
            "Epoch 37/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0198 - val_loss: 0.0206\n",
            "Epoch 38/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0197 - val_loss: 0.0207\n",
            "Epoch 39/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0197 - val_loss: 0.0211\n",
            "Epoch 40/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0198 - val_loss: 0.0207\n",
            "Epoch 41/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0196 - val_loss: 0.0206\n",
            "Epoch 42/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0197 - val_loss: 0.0210\n",
            "Epoch 43/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0198 - val_loss: 0.0203\n",
            "Epoch 44/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0197 - val_loss: 0.0203\n",
            "Epoch 45/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0196 - val_loss: 0.0207\n",
            "Epoch 46/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0196 - val_loss: 0.0203\n",
            "Epoch 47/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0196 - val_loss: 0.0203\n",
            "Epoch 48/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0196 - val_loss: 0.0202\n",
            "Epoch 49/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0195 - val_loss: 0.0202\n",
            "Epoch 50/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0195 - val_loss: 0.0206\n",
            "Epoch 51/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0195 - val_loss: 0.0208\n",
            "Epoch 52/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0195 - val_loss: 0.0202\n",
            "Epoch 53/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0195 - val_loss: 0.0203\n",
            "Epoch 54/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0194 - val_loss: 0.0202\n",
            "Epoch 55/1000\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0194 - val_loss: 0.0201\n",
            "Epoch 56/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0195 - val_loss: 0.0201\n",
            "Epoch 57/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0194 - val_loss: 0.0202\n",
            "Epoch 58/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0195 - val_loss: 0.0202\n",
            "Epoch 59/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0194 - val_loss: 0.0202\n",
            "Epoch 60/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0194 - val_loss: 0.0204\n",
            "Epoch 61/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0194 - val_loss: 0.0200\n",
            "Epoch 62/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0194 - val_loss: 0.0200\n",
            "Epoch 63/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0193 - val_loss: 0.0203\n",
            "Epoch 64/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0193 - val_loss: 0.0200\n",
            "Epoch 65/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0194 - val_loss: 0.0200\n",
            "Epoch 66/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0193 - val_loss: 0.0202\n",
            "Epoch 67/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0193 - val_loss: 0.0204\n",
            "Epoch 68/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0192 - val_loss: 0.0201\n",
            "Epoch 69/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0193 - val_loss: 0.0200\n",
            "Epoch 70/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0192 - val_loss: 0.0202\n",
            "Epoch 71/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0193 - val_loss: 0.0205\n",
            "Epoch 72/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0193 - val_loss: 0.0205\n",
            "Epoch 73/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0193 - val_loss: 0.0202\n",
            "Epoch 74/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0192 - val_loss: 0.0198\n",
            "Epoch 75/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0191 - val_loss: 0.0199\n",
            "Epoch 76/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0192 - val_loss: 0.0201\n",
            "Epoch 77/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0192 - val_loss: 0.0199\n",
            "Epoch 78/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0191 - val_loss: 0.0199\n",
            "Epoch 79/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0192 - val_loss: 0.0203\n",
            "Epoch 80/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0191 - val_loss: 0.0202\n",
            "Epoch 81/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0191 - val_loss: 0.0198\n",
            "Epoch 82/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0191 - val_loss: 0.0199\n",
            "Epoch 83/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0191 - val_loss: 0.0198\n",
            "Epoch 84/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0191 - val_loss: 0.0199\n",
            "Epoch 85/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0191 - val_loss: 0.0203\n",
            "Epoch 86/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0191 - val_loss: 0.0198\n",
            "Epoch 87/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0191 - val_loss: 0.0198\n",
            "Epoch 88/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0190 - val_loss: 0.0199\n",
            "Epoch 89/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0191 - val_loss: 0.0201\n",
            "Epoch 90/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0190 - val_loss: 0.0198\n",
            "Epoch 91/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0190 - val_loss: 0.0199\n",
            "Epoch 92/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0190 - val_loss: 0.0197\n",
            "Epoch 93/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0190 - val_loss: 0.0198\n",
            "Epoch 94/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0190 - val_loss: 0.0198\n",
            "Epoch 95/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0190 - val_loss: 0.0196\n",
            "Epoch 96/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0190 - val_loss: 0.0198\n",
            "Epoch 97/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0190 - val_loss: 0.0196\n",
            "Epoch 98/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0190 - val_loss: 0.0198\n",
            "Epoch 99/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0189 - val_loss: 0.0197\n",
            "Epoch 100/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0189 - val_loss: 0.0196\n",
            "Epoch 101/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0189 - val_loss: 0.0198\n",
            "Epoch 102/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0190 - val_loss: 0.0197\n",
            "Epoch 103/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0190 - val_loss: 0.0196\n",
            "Epoch 104/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0189 - val_loss: 0.0196\n",
            "Epoch 105/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0189 - val_loss: 0.0197\n",
            "Epoch 106/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0189 - val_loss: 0.0197\n",
            "Epoch 107/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0189 - val_loss: 0.0199\n",
            "Epoch 108/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0189 - val_loss: 0.0202\n",
            "Epoch 109/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0189 - val_loss: 0.0196\n",
            "Epoch 110/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0190 - val_loss: 0.0196\n",
            "Epoch 111/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0189 - val_loss: 0.0195\n",
            "Epoch 112/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0188 - val_loss: 0.0198\n",
            "Epoch 113/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0190 - val_loss: 0.0196\n",
            "Epoch 114/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0188 - val_loss: 0.0199\n",
            "Epoch 115/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0189 - val_loss: 0.0195\n",
            "Epoch 116/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0188 - val_loss: 0.0196\n",
            "Epoch 117/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0188 - val_loss: 0.0197\n",
            "Epoch 118/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0188 - val_loss: 0.0194\n",
            "Epoch 119/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0188 - val_loss: 0.0197\n",
            "Epoch 120/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0187 - val_loss: 0.0196\n",
            "Epoch 121/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0188 - val_loss: 0.0197\n",
            "Epoch 122/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0188 - val_loss: 0.0194\n",
            "Epoch 123/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0188 - val_loss: 0.0196\n",
            "Epoch 124/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0189 - val_loss: 0.0198\n",
            "Epoch 125/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0188 - val_loss: 0.0195\n",
            "Epoch 126/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0187 - val_loss: 0.0195\n",
            "Epoch 127/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0188 - val_loss: 0.0196\n",
            "Epoch 128/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0188 - val_loss: 0.0195\n",
            "Epoch 129/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0188 - val_loss: 0.0194\n",
            "Epoch 130/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0187 - val_loss: 0.0195\n",
            "Epoch 131/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0187 - val_loss: 0.0195\n",
            "Epoch 132/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0187 - val_loss: 0.0195\n",
            "Epoch 133/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0188 - val_loss: 0.0194\n",
            "Epoch 134/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0187 - val_loss: 0.0193\n",
            "Epoch 135/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0187 - val_loss: 0.0194\n",
            "Epoch 136/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0187 - val_loss: 0.0196\n",
            "Epoch 137/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0186 - val_loss: 0.0195\n",
            "Epoch 138/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0187 - val_loss: 0.0194\n",
            "Epoch 139/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0187 - val_loss: 0.0195\n",
            "Epoch 140/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0187 - val_loss: 0.0197\n",
            "Epoch 141/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0186 - val_loss: 0.0194\n",
            "Epoch 142/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0186 - val_loss: 0.0202\n",
            "Epoch 143/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0188 - val_loss: 0.0196\n",
            "Epoch 144/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0186 - val_loss: 0.0193\n",
            "Epoch 145/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0186 - val_loss: 0.0197\n",
            "Epoch 146/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0186 - val_loss: 0.0195\n",
            "Epoch 147/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0186 - val_loss: 0.0194\n",
            "Epoch 148/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0186 - val_loss: 0.0193\n",
            "Epoch 149/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0186 - val_loss: 0.0194\n",
            "Epoch 150/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0186 - val_loss: 0.0197\n",
            "Epoch 151/1000\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0186 - val_loss: 0.0201\n",
            "Epoch 152/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0187 - val_loss: 0.0195\n",
            "Epoch 153/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0185 - val_loss: 0.0195\n",
            "Epoch 154/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0186 - val_loss: 0.0194\n",
            "Epoch 155/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0186 - val_loss: 0.0195\n",
            "Epoch 156/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0186 - val_loss: 0.0195\n",
            "Epoch 157/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0186 - val_loss: 0.0194\n",
            "Epoch 158/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0187 - val_loss: 0.0195\n",
            "Epoch 159/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0186 - val_loss: 0.0193\n",
            "Epoch 160/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0186 - val_loss: 0.0195\n",
            "Epoch 161/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0186 - val_loss: 0.0197\n",
            "Epoch 162/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0185 - val_loss: 0.0196\n",
            "Epoch 163/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0185 - val_loss: 0.0195\n",
            "Epoch 164/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0186 - val_loss: 0.0192\n",
            "Epoch 165/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0184 - val_loss: 0.0193\n",
            "Epoch 166/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0185 - val_loss: 0.0203\n",
            "Epoch 167/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0185 - val_loss: 0.0196\n",
            "Epoch 168/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0185 - val_loss: 0.0194\n",
            "Epoch 169/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0186 - val_loss: 0.0194\n",
            "Epoch 170/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0186 - val_loss: 0.0193\n",
            "Epoch 171/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0185 - val_loss: 0.0193\n",
            "Epoch 172/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0185 - val_loss: 0.0196\n",
            "Epoch 173/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0185 - val_loss: 0.0193\n",
            "Epoch 174/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0186 - val_loss: 0.0192\n",
            "Epoch 175/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0184 - val_loss: 0.0192\n",
            "Epoch 176/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0185 - val_loss: 0.0193\n",
            "Epoch 177/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0185 - val_loss: 0.0192\n",
            "Epoch 178/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0185 - val_loss: 0.0194\n",
            "Epoch 179/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0184 - val_loss: 0.0193\n",
            "Epoch 180/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0184 - val_loss: 0.0192\n",
            "Epoch 181/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0184 - val_loss: 0.0193\n",
            "Epoch 182/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0185 - val_loss: 0.0192\n",
            "Epoch 183/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0185 - val_loss: 0.0193\n",
            "Epoch 184/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0185 - val_loss: 0.0193\n",
            "Epoch 185/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0184 - val_loss: 0.0192\n",
            "Epoch 186/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0185 - val_loss: 0.0193\n",
            "Epoch 187/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0184 - val_loss: 0.0194\n",
            "Epoch 188/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0185 - val_loss: 0.0192\n",
            "Epoch 189/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0185 - val_loss: 0.0193\n",
            "Epoch 190/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0184 - val_loss: 0.0197\n",
            "Epoch 191/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0184 - val_loss: 0.0194\n",
            "Epoch 192/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0185 - val_loss: 0.0191\n",
            "Epoch 193/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0184 - val_loss: 0.0191\n",
            "Epoch 194/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0183 - val_loss: 0.0198\n",
            "Epoch 195/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0184 - val_loss: 0.0193\n",
            "Epoch 196/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0184 - val_loss: 0.0192\n",
            "Epoch 197/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0184 - val_loss: 0.0191\n",
            "Epoch 198/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0184 - val_loss: 0.0194\n",
            "Epoch 199/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0184 - val_loss: 0.0192\n",
            "Epoch 200/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0184 - val_loss: 0.0191\n",
            "Epoch 201/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0183 - val_loss: 0.0193\n",
            "Epoch 202/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0184 - val_loss: 0.0194\n",
            "Epoch 203/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0183 - val_loss: 0.0191\n",
            "Epoch 204/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0183 - val_loss: 0.0191\n",
            "Epoch 205/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0183 - val_loss: 0.0194\n",
            "Epoch 206/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0184 - val_loss: 0.0190\n",
            "Epoch 207/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0184 - val_loss: 0.0198\n",
            "Epoch 208/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0184 - val_loss: 0.0191\n",
            "Epoch 209/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0183 - val_loss: 0.0194\n",
            "Epoch 210/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0183 - val_loss: 0.0205\n",
            "Epoch 211/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0184 - val_loss: 0.0193\n",
            "Epoch 212/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0184 - val_loss: 0.0192\n",
            "Epoch 213/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0184 - val_loss: 0.0192\n",
            "Epoch 214/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0184 - val_loss: 0.0192\n",
            "Epoch 215/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0183 - val_loss: 0.0190\n",
            "Epoch 216/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0183 - val_loss: 0.0191\n",
            "Epoch 217/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0183 - val_loss: 0.0191\n",
            "Epoch 218/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0184 - val_loss: 0.0190\n",
            "Epoch 219/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0184 - val_loss: 0.0190\n",
            "Epoch 220/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0182 - val_loss: 0.0193\n",
            "Epoch 221/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0182 - val_loss: 0.0190\n",
            "Epoch 222/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0183 - val_loss: 0.0190\n",
            "Epoch 223/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0183 - val_loss: 0.0191\n",
            "Epoch 224/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0184 - val_loss: 0.0192\n",
            "Epoch 225/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0183 - val_loss: 0.0190\n",
            "Epoch 226/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0183 - val_loss: 0.0191\n",
            "Epoch 227/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0183 - val_loss: 0.0191\n",
            "Epoch 228/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0183 - val_loss: 0.0190\n",
            "Epoch 229/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0183 - val_loss: 0.0190\n",
            "Epoch 230/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0183 - val_loss: 0.0192\n",
            "Epoch 231/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0183 - val_loss: 0.0194\n",
            "Epoch 232/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0190\n",
            "Epoch 233/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0184 - val_loss: 0.0192\n",
            "Epoch 234/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0182 - val_loss: 0.0191\n",
            "Epoch 235/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0192\n",
            "Epoch 236/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0183 - val_loss: 0.0191\n",
            "Epoch 237/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0183 - val_loss: 0.0192\n",
            "Epoch 238/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0182 - val_loss: 0.0190\n",
            "Epoch 239/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0193\n",
            "Epoch 240/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0182 - val_loss: 0.0194\n",
            "Epoch 241/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0183 - val_loss: 0.0195\n",
            "Epoch 242/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0192\n",
            "Epoch 243/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0182 - val_loss: 0.0191\n",
            "Epoch 244/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0182 - val_loss: 0.0194\n",
            "Epoch 245/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0183 - val_loss: 0.0190\n",
            "Epoch 246/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0182 - val_loss: 0.0191\n",
            "Epoch 247/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 248/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0182 - val_loss: 0.0192\n",
            "Epoch 249/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0182 - val_loss: 0.0190\n",
            "Epoch 250/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0182 - val_loss: 0.0191\n",
            "Epoch 251/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0183 - val_loss: 0.0190\n",
            "Epoch 252/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0182 - val_loss: 0.0200\n",
            "Epoch 253/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0183 - val_loss: 0.0189\n",
            "Epoch 254/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0191\n",
            "Epoch 255/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0192\n",
            "Epoch 256/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0182 - val_loss: 0.0190\n",
            "Epoch 257/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 258/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0182 - val_loss: 0.0189\n",
            "Epoch 259/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0182 - val_loss: 0.0193\n",
            "Epoch 260/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0182 - val_loss: 0.0189\n",
            "Epoch 261/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0182 - val_loss: 0.0189\n",
            "Epoch 262/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 263/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0182 - val_loss: 0.0189\n",
            "Epoch 264/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0181 - val_loss: 0.0196\n",
            "Epoch 265/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0191\n",
            "Epoch 266/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0182 - val_loss: 0.0192\n",
            "Epoch 267/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0181 - val_loss: 0.0190\n",
            "Epoch 268/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0190\n",
            "Epoch 269/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0189\n",
            "Epoch 270/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0189\n",
            "Epoch 271/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0194\n",
            "Epoch 272/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0190\n",
            "Epoch 273/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0182 - val_loss: 0.0190\n",
            "Epoch 274/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0181 - val_loss: 0.0190\n",
            "Epoch 275/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0194\n",
            "Epoch 276/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 277/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0181 - val_loss: 0.0192\n",
            "Epoch 278/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0192\n",
            "Epoch 279/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0190\n",
            "Epoch 280/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 281/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 282/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0190\n",
            "Epoch 283/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0182 - val_loss: 0.0194\n",
            "Epoch 284/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0189\n",
            "Epoch 285/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0197\n",
            "Epoch 286/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 287/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0189\n",
            "Epoch 288/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 289/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0190\n",
            "Epoch 290/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0190\n",
            "Epoch 291/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0181 - val_loss: 0.0194\n",
            "Epoch 292/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0191\n",
            "Epoch 293/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 294/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0181 - val_loss: 0.0192\n",
            "Epoch 295/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 296/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 297/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 298/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0191\n",
            "Epoch 299/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 300/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0192\n",
            "Epoch 301/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0189\n",
            "Epoch 302/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0190\n",
            "Epoch 303/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 304/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0190\n",
            "Epoch 305/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 306/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0190\n",
            "Epoch 307/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 308/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 309/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0187\n",
            "Epoch 310/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0187\n",
            "Epoch 311/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0181 - val_loss: 0.0189\n",
            "Epoch 312/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0181 - val_loss: 0.0192\n",
            "Epoch 313/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0189\n",
            "Epoch 314/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0181 - val_loss: 0.0188\n",
            "Epoch 315/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0189\n",
            "Epoch 316/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0180 - val_loss: 0.0189\n",
            "Epoch 317/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0181 - val_loss: 0.0188\n",
            "Epoch 318/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0180 - val_loss: 0.0196\n",
            "Epoch 319/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0181 - val_loss: 0.0188\n",
            "Epoch 320/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0190\n",
            "Epoch 321/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0180 - val_loss: 0.0187\n",
            "Epoch 322/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 323/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0180 - val_loss: 0.0190\n",
            "Epoch 324/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0187\n",
            "Epoch 325/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0189\n",
            "Epoch 326/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 327/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0180 - val_loss: 0.0189\n",
            "Epoch 328/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0190\n",
            "Epoch 329/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0190\n",
            "Epoch 330/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 331/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0179 - val_loss: 0.0188\n",
            "Epoch 332/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0182 - val_loss: 0.0188\n",
            "Epoch 333/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0189\n",
            "Epoch 334/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0179 - val_loss: 0.0192\n",
            "Epoch 335/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0181 - val_loss: 0.0187\n",
            "Epoch 336/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0187\n",
            "Epoch 337/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0187\n",
            "Epoch 338/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0180 - val_loss: 0.0189\n",
            "Epoch 339/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0179 - val_loss: 0.0187\n",
            "Epoch 340/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0179 - val_loss: 0.0187\n",
            "Epoch 341/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0179 - val_loss: 0.0187\n",
            "Epoch 342/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0179 - val_loss: 0.0188\n",
            "Epoch 343/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0179 - val_loss: 0.0188\n",
            "Epoch 344/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 345/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0187\n",
            "Epoch 346/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 347/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0189\n",
            "Epoch 348/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 349/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 350/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0179 - val_loss: 0.0190\n",
            "Epoch 351/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0179 - val_loss: 0.0187\n",
            "Epoch 352/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0179 - val_loss: 0.0186\n",
            "Epoch 353/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 354/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 355/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 356/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0179 - val_loss: 0.0187\n",
            "Epoch 357/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0179 - val_loss: 0.0188\n",
            "Epoch 358/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0179 - val_loss: 0.0188\n",
            "Epoch 359/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 360/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0179 - val_loss: 0.0190\n",
            "Epoch 361/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0187\n",
            "Epoch 362/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 363/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0189\n",
            "Epoch 364/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0180 - val_loss: 0.0191\n",
            "Epoch 365/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0187\n",
            "Epoch 366/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0180 - val_loss: 0.0195\n",
            "Epoch 367/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0180 - val_loss: 0.0187\n",
            "Epoch 368/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0190\n",
            "Epoch 369/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0179 - val_loss: 0.0189\n",
            "Epoch 370/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0179 - val_loss: 0.0188\n",
            "Epoch 371/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0179 - val_loss: 0.0190\n",
            "Epoch 372/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0180 - val_loss: 0.0192\n",
            "Epoch 373/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0179 - val_loss: 0.0189\n",
            "Epoch 374/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0179 - val_loss: 0.0187\n",
            "Epoch 375/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0179 - val_loss: 0.0187\n",
            "Epoch 376/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0179 - val_loss: 0.0191\n",
            "Epoch 377/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0179 - val_loss: 0.0190\n",
            "Epoch 378/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 379/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0179 - val_loss: 0.0187\n",
            "Epoch 380/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0179 - val_loss: 0.0192\n",
            "Epoch 381/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0179 - val_loss: 0.0186\n",
            "Epoch 382/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0179 - val_loss: 0.0188\n",
            "Epoch 383/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0179 - val_loss: 0.0188\n",
            "Epoch 384/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0188\n",
            "Epoch 385/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0189\n",
            "Epoch 386/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0179 - val_loss: 0.0191\n",
            "Epoch 387/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0179 - val_loss: 0.0187\n",
            "Epoch 388/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0179 - val_loss: 0.0186\n",
            "Epoch 389/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 390/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 391/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0179 - val_loss: 0.0187\n",
            "Epoch 392/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 393/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0179 - val_loss: 0.0188\n",
            "Epoch 394/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0188\n",
            "Epoch 395/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0180 - val_loss: 0.0188\n",
            "Epoch 396/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0185\n",
            "Epoch 397/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0179 - val_loss: 0.0186\n",
            "Epoch 398/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 399/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0179 - val_loss: 0.0189\n",
            "Epoch 400/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0179 - val_loss: 0.0186\n",
            "Epoch 401/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0185\n",
            "Epoch 402/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 403/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 404/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 405/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 406/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 407/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 408/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 409/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0191\n",
            "Epoch 410/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 411/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0188\n",
            "Epoch 412/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 413/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 414/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 415/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0196\n",
            "Epoch 416/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0179 - val_loss: 0.0186\n",
            "Epoch 417/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0188\n",
            "Epoch 418/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 419/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 420/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0188\n",
            "Epoch 421/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0188\n",
            "Epoch 422/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 423/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 424/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0179 - val_loss: 0.0186\n",
            "Epoch 425/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0190\n",
            "Epoch 426/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 427/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 428/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 429/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0189\n",
            "Epoch 430/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0185\n",
            "Epoch 431/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 432/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0179 - val_loss: 0.0188\n",
            "Epoch 433/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 434/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 435/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0177 - val_loss: 0.0188\n",
            "Epoch 436/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0188\n",
            "Epoch 437/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 438/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 439/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 440/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 441/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0177 - val_loss: 0.0187\n",
            "Epoch 442/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0179 - val_loss: 0.0188\n",
            "Epoch 443/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0187\n",
            "Epoch 444/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0185\n",
            "Epoch 445/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 446/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0179 - val_loss: 0.0185\n",
            "Epoch 447/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0185\n",
            "Epoch 448/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0187\n",
            "Epoch 449/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0185\n",
            "Epoch 450/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0188\n",
            "Epoch 451/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 452/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 453/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0185\n",
            "Epoch 454/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0189\n",
            "Epoch 455/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0185\n",
            "Epoch 456/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 457/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0188\n",
            "Epoch 458/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 459/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0187\n",
            "Epoch 460/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0188\n",
            "Epoch 461/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0189\n",
            "Epoch 462/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0185\n",
            "Epoch 463/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 464/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 465/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0177 - val_loss: 0.0187\n",
            "Epoch 466/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 467/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0188\n",
            "Epoch 468/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0189\n",
            "Epoch 469/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 470/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0189\n",
            "Epoch 471/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 472/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 473/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 474/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 475/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 476/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 477/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0185\n",
            "Epoch 478/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 479/1000\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 480/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0177 - val_loss: 0.0187\n",
            "Epoch 481/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 482/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0189\n",
            "Epoch 483/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 484/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0177 - val_loss: 0.0184\n",
            "Epoch 485/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0187\n",
            "Epoch 486/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0177 - val_loss: 0.0193\n",
            "Epoch 487/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 488/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 489/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 490/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 491/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 492/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 493/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0177 - val_loss: 0.0188\n",
            "Epoch 494/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0186\n",
            "Epoch 495/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0184\n",
            "Epoch 496/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 497/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 498/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 499/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 500/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 501/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 502/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 503/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 504/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0190\n",
            "Epoch 505/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 506/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 507/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 508/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0188\n",
            "Epoch 509/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 510/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0178 - val_loss: 0.0185\n",
            "Epoch 511/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 512/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 513/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 514/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 515/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0177 - val_loss: 0.0190\n",
            "Epoch 516/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0187\n",
            "Epoch 517/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 518/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0187\n",
            "Epoch 519/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 520/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 521/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 522/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 523/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 524/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 525/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0184\n",
            "Epoch 526/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 527/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 528/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0187\n",
            "Epoch 529/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0187\n",
            "Epoch 530/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0184\n",
            "Epoch 531/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 532/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0188\n",
            "Epoch 533/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0177 - val_loss: 0.0184\n",
            "Epoch 534/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0176 - val_loss: 0.0189\n",
            "Epoch 535/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 536/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0186\n",
            "Epoch 537/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0186\n",
            "Epoch 538/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0193\n",
            "Epoch 539/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 540/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0187\n",
            "Epoch 541/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 542/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 543/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0187\n",
            "Epoch 544/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0184\n",
            "Epoch 545/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0186\n",
            "Epoch 546/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0187\n",
            "Epoch 547/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0187\n",
            "Epoch 548/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 549/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0177 - val_loss: 0.0184\n",
            "Epoch 550/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 551/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 552/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 553/1000\n",
            "215/215 [==============================] - 8s 40ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 554/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 555/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 556/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 557/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 558/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 559/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0186\n",
            "Epoch 560/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 561/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0178 - val_loss: 0.0186\n",
            "Epoch 562/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0186\n",
            "Epoch 563/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 564/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 565/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0195\n",
            "Epoch 566/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0192\n",
            "Epoch 567/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 568/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 569/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0176 - val_loss: 0.0187\n",
            "Epoch 570/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 571/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 572/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0187\n",
            "Epoch 573/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 574/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 575/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0177 - val_loss: 0.0184\n",
            "Epoch 576/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0177 - val_loss: 0.0185\n",
            "Epoch 577/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0186\n",
            "Epoch 578/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0186\n",
            "Epoch 579/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 580/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0187\n",
            "Epoch 581/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0177 - val_loss: 0.0184\n",
            "Epoch 582/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 583/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0186\n",
            "Epoch 584/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 585/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 586/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 587/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 588/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0183\n",
            "Epoch 589/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 590/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 591/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 592/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 593/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0186\n",
            "Epoch 594/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0192\n",
            "Epoch 595/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 596/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 597/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 598/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0186\n",
            "Epoch 599/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 600/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 601/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 602/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 603/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 604/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 605/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 606/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 607/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 608/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 609/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0188\n",
            "Epoch 610/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0186\n",
            "Epoch 611/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 612/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0188\n",
            "Epoch 613/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0184\n",
            "Epoch 614/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 615/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 616/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0182\n",
            "Epoch 617/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 618/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0183\n",
            "Epoch 619/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0182\n",
            "Epoch 620/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 621/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 622/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 623/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 624/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 625/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 626/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 627/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 628/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0187\n",
            "Epoch 629/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 630/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0188\n",
            "Epoch 631/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0189\n",
            "Epoch 632/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 633/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 634/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 635/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0187\n",
            "Epoch 636/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 637/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 638/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 639/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0176 - val_loss: 0.0183\n",
            "Epoch 640/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 641/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0189\n",
            "Epoch 642/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 643/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0185\n",
            "Epoch 644/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 645/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0176 - val_loss: 0.0183\n",
            "Epoch 646/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 647/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 648/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0182\n",
            "Epoch 649/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 650/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0182\n",
            "Epoch 651/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0189\n",
            "Epoch 652/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 653/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 654/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0186\n",
            "Epoch 655/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0176 - val_loss: 0.0183\n",
            "Epoch 656/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 657/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 658/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 659/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0187\n",
            "Epoch 660/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 661/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 662/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0182\n",
            "Epoch 663/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0189\n",
            "Epoch 664/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 665/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0187\n",
            "Epoch 666/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 667/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0174 - val_loss: 0.0185\n",
            "Epoch 668/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 669/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 670/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 671/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 672/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 673/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 674/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 675/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 676/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 677/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 678/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 679/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 680/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0186\n",
            "Epoch 681/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 682/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0176 - val_loss: 0.0182\n",
            "Epoch 683/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 684/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 685/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 686/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 687/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 688/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 689/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 690/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0182\n",
            "Epoch 691/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 692/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 693/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0185\n",
            "Epoch 694/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 695/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0185\n",
            "Epoch 696/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0186\n",
            "Epoch 697/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0185\n",
            "Epoch 698/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 699/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0185\n",
            "Epoch 700/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0182\n",
            "Epoch 701/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0186\n",
            "Epoch 702/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0188\n",
            "Epoch 703/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 704/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 705/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0185\n",
            "Epoch 706/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0182\n",
            "Epoch 707/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 708/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 709/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 710/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0182\n",
            "Epoch 711/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0174 - val_loss: 0.0185\n",
            "Epoch 712/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 713/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 714/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0189\n",
            "Epoch 715/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 716/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0189\n",
            "Epoch 717/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 718/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 719/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 720/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 721/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0186\n",
            "Epoch 722/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 723/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 724/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 725/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 726/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 727/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0186\n",
            "Epoch 728/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0186\n",
            "Epoch 729/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 730/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 731/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 732/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 733/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 734/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 735/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 736/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0188\n",
            "Epoch 737/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 738/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 739/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 740/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 741/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 742/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 743/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 744/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 745/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 746/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 747/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 748/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 749/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0176 - val_loss: 0.0186\n",
            "Epoch 750/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 751/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 752/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 753/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 754/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 755/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 756/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0185\n",
            "Epoch 757/1000\n",
            "215/215 [==============================] - 9s 43ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 758/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0185\n",
            "Epoch 759/1000\n",
            "215/215 [==============================] - 9s 41ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 760/1000\n",
            "215/215 [==============================] - 10s 46ms/step - loss: 0.0175 - val_loss: 0.0183\n",
            "Epoch 761/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 762/1000\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 763/1000\n",
            "215/215 [==============================] - 9s 43ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 764/1000\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 765/1000\n",
            "215/215 [==============================] - 9s 42ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 766/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 767/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 768/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0175 - val_loss: 0.0182\n",
            "Epoch 769/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0186\n",
            "Epoch 770/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 771/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0181\n",
            "Epoch 772/1000\n",
            "215/215 [==============================] - 10s 46ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 773/1000\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 774/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0188\n",
            "Epoch 775/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 776/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0186\n",
            "Epoch 777/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 778/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 779/1000\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0174 - val_loss: 0.0186\n",
            "Epoch 780/1000\n",
            "215/215 [==============================] - 9s 43ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 781/1000\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 782/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 783/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0181\n",
            "Epoch 784/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 785/1000\n",
            "215/215 [==============================] - 9s 42ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 786/1000\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0174 - val_loss: 0.0181\n",
            "Epoch 787/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 788/1000\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 789/1000\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 790/1000\n",
            "215/215 [==============================] - 9s 40ms/step - loss: 0.0174 - val_loss: 0.0187\n",
            "Epoch 791/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 792/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 793/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 794/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 795/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 796/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 797/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 798/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0175 - val_loss: 0.0184\n",
            "Epoch 799/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 800/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 801/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 802/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 803/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 804/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0185\n",
            "Epoch 805/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 806/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 807/1000\n",
            "215/215 [==============================] - 9s 41ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 808/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0181\n",
            "Epoch 809/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 810/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 811/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 812/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 813/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 814/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 815/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 816/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 817/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 818/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 819/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0181\n",
            "Epoch 820/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 821/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 822/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 823/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 824/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 825/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 826/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 827/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 828/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 829/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 830/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 831/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 832/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 833/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 834/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 835/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 836/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 837/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0182\n",
            "Epoch 838/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 839/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 840/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0187\n",
            "Epoch 841/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0181\n",
            "Epoch 842/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0191\n",
            "Epoch 843/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 844/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 845/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 846/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0181\n",
            "Epoch 847/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 848/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 849/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 850/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 851/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0174 - val_loss: 0.0183\n",
            "Epoch 852/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 853/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 854/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 855/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0185\n",
            "Epoch 856/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0185\n",
            "Epoch 857/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 858/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 859/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 860/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 861/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 862/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 863/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0187\n",
            "Epoch 864/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 865/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 866/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0174 - val_loss: 0.0181\n",
            "Epoch 867/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 868/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 869/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 870/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0186\n",
            "Epoch 871/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 872/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 873/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 874/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 875/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 876/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 877/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 878/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 879/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0186\n",
            "Epoch 880/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 881/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 882/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 883/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 884/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 885/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 886/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 887/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 888/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 889/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 890/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 891/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 892/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 893/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 894/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 895/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 896/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 897/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 898/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 899/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 900/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 901/1000\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 902/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 903/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 904/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 905/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0180\n",
            "Epoch 906/1000\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 907/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 908/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0180\n",
            "Epoch 909/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0183\n",
            "Epoch 910/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 911/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0180\n",
            "Epoch 912/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 913/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 914/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 915/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0183\n",
            "Epoch 916/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0183\n",
            "Epoch 917/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 918/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 919/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0174 - val_loss: 0.0184\n",
            "Epoch 920/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 921/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0183\n",
            "Epoch 922/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0172 - val_loss: 0.0186\n",
            "Epoch 923/1000\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.0173 - val_loss: 0.0184\n",
            "Epoch 924/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0185\n",
            "Epoch 925/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 926/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 927/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 928/1000\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.0172 - val_loss: 0.0185\n",
            "Epoch 929/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 930/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0185\n",
            "Epoch 931/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 932/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 933/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0183\n",
            "Epoch 934/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0183\n",
            "Epoch 935/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 936/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 937/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0180\n",
            "Epoch 938/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0183\n",
            "Epoch 939/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 940/1000\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 941/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 942/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 943/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 944/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 945/1000\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 946/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 947/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 948/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 949/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0172 - val_loss: 0.0180\n",
            "Epoch 950/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 951/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0171 - val_loss: 0.0182\n",
            "Epoch 952/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 953/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0180\n",
            "Epoch 954/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0183\n",
            "Epoch 955/1000\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.0172 - val_loss: 0.0180\n",
            "Epoch 956/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0185\n",
            "Epoch 957/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 958/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 959/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 960/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 961/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0172 - val_loss: 0.0180\n",
            "Epoch 962/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 963/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 964/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0172 - val_loss: 0.0180\n",
            "Epoch 965/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 966/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0180\n",
            "Epoch 967/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 968/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 969/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0188\n",
            "Epoch 970/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0180\n",
            "Epoch 971/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0181\n",
            "Epoch 972/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 973/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 974/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 975/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 976/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 977/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 978/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0180\n",
            "Epoch 979/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0171 - val_loss: 0.0182\n",
            "Epoch 980/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 981/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 982/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 983/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0172 - val_loss: 0.0183\n",
            "Epoch 984/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 985/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 986/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0172 - val_loss: 0.0180\n",
            "Epoch 987/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 988/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 989/1000\n",
            "215/215 [==============================] - 8s 35ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 990/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 991/1000\n",
            "215/215 [==============================] - 8s 38ms/step - loss: 0.0173 - val_loss: 0.0186\n",
            "Epoch 992/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 993/1000\n",
            "215/215 [==============================] - 8s 39ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 994/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0182\n",
            "Epoch 995/1000\n",
            "215/215 [==============================] - 8s 37ms/step - loss: 0.0171 - val_loss: 0.0182\n",
            "Epoch 996/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0180\n",
            "Epoch 997/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0173 - val_loss: 0.0182\n",
            "Epoch 998/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0181\n",
            "Epoch 999/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0183\n",
            "Epoch 1000/1000\n",
            "215/215 [==============================] - 8s 36ms/step - loss: 0.0172 - val_loss: 0.0180\n",
            "The time of execution of the fine-tuning program is: 8076.957766056061 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing NBS"
      ],
      "metadata": {
        "id": "nNsepatu0du0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_input = []\n",
        "val_input = []\n",
        "train_output = []\n",
        "val_output = []\n",
        "\n",
        "from tensorflow import keras\n",
        "#model_number = 6\n",
        "#autoencoder = keras.models.load_model(file_path + '7 Fine tuning/' + 'autoencoder_fine_tuned_'+str(model_number))"
      ],
      "metadata": {
        "id": "AWMso_9APyCi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "Image.MAX_IMAGE_PIXELS = None\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "import time\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "\n",
        "def crop(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "    for j in range(0,int(height/n_size)):\n",
        "        for i in range(0,int(width/n_size)):\n",
        "            im1 = im.crop((0 + (n_size*i), 0 + (n_size*j), n_size + (n_size*i), n_size + (n_size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            im1 = im1/255\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "def normalize(arr):\n",
        "    \"\"\"\n",
        "    Linear normalization\n",
        "    http://en.wikipedia.org/wiki/Normalization_%28image_processing%29\n",
        "    \"\"\"\n",
        "    arr = arr.astype('float')\n",
        "    # Do not touch the alpha channel\n",
        "    for i in range(3):\n",
        "        minval = arr[...,i].min()\n",
        "        maxval = arr[...,i].max()\n",
        "        if minval != maxval:\n",
        "            arr[...,i] -= minval\n",
        "            arr[...,i] *= (255.0/(maxval-minval))\n",
        "    return arr"
      ],
      "metadata": {
        "id": "VoGf_ChXb5CA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "directory = file_path + '7 Fine tuning/test/MFP_J_stitched_v2.tif'\n",
        "dirty = ImageOps.grayscale(Image.open(directory))\n",
        "dirty = np.array(dirty)\n",
        "dirty = Image.fromarray(normalize(dirty).astype('uint8'))\n",
        "\n",
        "w_dirty, h_dirty = dirty.size\n",
        "\n",
        "model = 6\n",
        "METRIC = []\n",
        "\n",
        "from tensorflow import keras\n",
        "autoencoder = keras.models.load_model(file_path + '7 Fine tuning/' + 'v3_autoencoder_'+str(model_number)+'_b')\n",
        "if model == 1:\n",
        "    n_size = 32\n",
        "if model == 2:\n",
        "    n_size = 32\n",
        "if model == 3:\n",
        "    n_size = 64\n",
        "if model == 4:\n",
        "    n_size = 64\n",
        "if model == 5:\n",
        "    n_size = 128\n",
        "if model == 6:\n",
        "    n_size = 128\n",
        "if model == 7:\n",
        "    n_size = 256\n",
        "if model == 8:\n",
        "    n_size = 256\n",
        "\n",
        "xx = int(w_dirty/n_size)\n",
        "final=[]\n",
        "\n",
        "for portion in range(0,xx):\n",
        "    #print(\"current portion to clean:\", str(portion))\n",
        "\n",
        "    im1 = dirty.crop((n_size*portion, 0, (n_size*portion) + n_size, h_dirty-128))\n",
        "    w1, h1 = im1.size\n",
        "    w = int(w1/n_size)\n",
        "    h = int(h1/n_size)\n",
        "\n",
        "    neverbeforeseen = np.array(crop(im1))\n",
        "    encoded_imgs = autoencoder.encoder(neverbeforeseen).numpy()\n",
        "    decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
        "\n",
        "    col = np.vstack((decoded_imgs[0],decoded_imgs[1]))\n",
        "    for i in range(2,h):\n",
        "        col = np.vstack((col,decoded_imgs[i]))\n",
        "\n",
        "    y = np.where(col > 0.5,1,0) #round the values\n",
        "    y = (y * 255).astype('uint8')\n",
        "    if portion == 0:\n",
        "        final = y\n",
        "    if portion > 0:\n",
        "        final = np.hstack((final,y))\n",
        "\n",
        "final = np.squeeze(final)\n",
        "reconstructed = Image.fromarray(final)\n",
        "reconstructed.save(file_path + '7 Fine tuning/test/v3_CLEAN_MFP_J_stitched_v2.tif')"
      ],
      "metadata": {
        "id": "kld1Ky2az8-w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tNOiAZQ9Spn9"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}