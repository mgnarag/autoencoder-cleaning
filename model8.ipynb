{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "authorship_tag": "ABX9TyO+KBTdV7PlW2SwOPOPRR+/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mgnarag/binarization-autoencoder/blob/main/model8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWqyw4uBKphg"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls drive/My\\ Drive\n",
        "file_path = \"/content/drive/My Drive/Architectural_designs/one quadrant/\""
      ],
      "metadata": {
        "id": "w4XNRD3IKvQV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "epoch = 100\n",
        "model_number = 7\n",
        "size = 256\n",
        "\n",
        "def crop(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "\n",
        "    for j in np.arange(0,int(height/size)+1,0.25):\n",
        "        for i in np.arange(0,int(width/size)+1,0.25):\n",
        "            im1 = im.crop((0 + (size*i), 0 + (size*j), size + (size*i), size + (size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            im1 = im1/255\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "def crop1(im):\n",
        "    width, height = im.size\n",
        "    data = []\n",
        "\n",
        "    for j in np.arange(0,int(height/size)+1,0.5):\n",
        "        for i in np.arange(0,int(width/size)+1,0.5):\n",
        "            im1 = im.crop((0 + (size*i), 0 + (size*j), size + (size*i), size + (size*j)))\n",
        "            im1 = np.array(im1)\n",
        "            im1 = im1.astype(np.float32)\n",
        "            im1 = im1/255\n",
        "            data.append(im1)\n",
        "    return data\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "train_input = np.array(crop(Image.open(file_path + \"final_input_train.png\")))\n",
        "print(\"Done reading the  training input of size = \", train_input.shape)\n",
        "\n",
        "train_output = np.array(crop(Image.open(file_path + \"cleaned_output_train.png\")))\n",
        "print(\"Done reading the  training out of size = \", train_output.shape)\n",
        "\n",
        "test_input = np.array(crop(Image.open(file_path + \"final_input_test.png\")))\n",
        "print(\"Done reading the  test input of size = \", test_input.shape)\n",
        "\n",
        "test_output = np.array(crop(Image.open(file_path + \"cleaned_output_test.png\")))\n",
        "print(\"Done reading the  test output of size = \", test_output.shape)\n",
        "'''\n",
        "\n",
        "train_input = np.array(crop(ImageOps.grayscale(Image.open(file_path + \"final_input_train.png\"))))\n",
        "print(\"Done reading the  training input of size = \", train_input.shape)\n",
        "\n",
        "train_output = np.array(crop(ImageOps.grayscale(Image.open(file_path + \"cleaned_output_train.png\"))))\n",
        "print(\"Done reading the  training out of size = \", train_output.shape)\n",
        "\n",
        "\n",
        "test_input = np.array(crop1(ImageOps.grayscale(Image.open(file_path + \"final_input_test.png\"))))\n",
        "print(\"Done reading the  test input of size = \", test_input.shape)\n",
        "\n",
        "test_output = np.array(crop1(ImageOps.grayscale(Image.open(file_path + \"cleaned_output_test.png\"))))\n",
        "print(\"Done reading the  test output of size = \", test_output.shape)\n"
      ],
      "metadata": {
        "id": "vWGhCSd6KwLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(10, 4))\n",
        "for i in range(0,10):\n",
        "\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.title(\"input\")\n",
        "    plt.imshow((train_input[i+10]))\n",
        "    plt.gray()\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "\n",
        "    bx = plt.subplot(2, n, i + n + 1)\n",
        "    plt.title(\"output\")\n",
        "    plt.imshow((train_output[i+10]))\n",
        "    plt.gray()\n",
        "    bx.get_xaxis().set_visible(False)\n",
        "    bx.get_yaxis().set_visible(False)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "U8ejEavIKxGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "class autoenc(Model):\n",
        "  def __init__(self):\n",
        "    super(autoenc, self).__init__()\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Input(shape=(size, size, 1)),\n",
        "      layers.Conv2D(64, (3, 3), activation='relu', padding='same', strides=2)])\n",
        "\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Conv2DTranspose(64, kernel_size=3, strides=2, activation='relu', padding='same'),\n",
        "      layers.Conv2D(1, kernel_size=(3, 3), activation='sigmoid', padding='same')])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = autoenc()\n",
        "\n",
        "\n",
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
        "\n",
        "model = autoencoder.fit(train_input, train_output,\n",
        "                epochs=epoch,\n",
        "                shuffle=True,\n",
        "                validation_data=(test_input, test_output))\n",
        "\n",
        "autoencoder.encoder.summary()\n",
        "\n",
        "\n",
        "\n",
        "autoencoder.save(file_path + '1 Models/' + 'autoencoder_1')\n",
        "\n",
        "loss = model.history['loss']\n",
        "loss = pd.DataFrame(loss)\n",
        "loss.to_csv(file_path + '2 Loss/'+'loss_1.csv')\n",
        "val_loss = model.history['val_loss']\n",
        "val_loss = pd.DataFrame(val_loss)\n",
        "val_loss.to_csv(file_path + '3 Validation loss/' +'val_loss_1.csv')\n",
        "\n",
        "# record end time\n",
        "end = time.time()\n",
        "\n",
        "print(\"The time of execution of above program is :\",\n",
        "      (end-start), \"seconds\")\n"
      ],
      "metadata": {
        "id": "guPIoJS7KyUK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}